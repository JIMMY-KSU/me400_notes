
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Root Finding &#8212; ME 400 Course Notes Fall 2017 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     'Fall 2017',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Optimization" href="Optimization.html" />
    <link rel="prev" title="Linear Systems" href="Linear_Systems.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="section" id="Root-Finding">
<h1>Root Finding<a class="headerlink" href="#Root-Finding" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Overview,-Objectives,-and-Key-Terms">
<h2>Overview, Objectives, and Key Terms<a class="headerlink" href="#Overview,-Objectives,-and-Key-Terms" title="Permalink to this headline">¶</a></h2>
<p>In <a class="reference internal" href="ME400_Lecture_19.html"><span class="doc">Lecture 19</span></a>, SymPy was applied to perform
symbolic differentuation, and in <a class="reference external" href="ME400_Lecture_21.ipynb">Lecture
21</a>, finite-difference approximations were
developed to perform numerical differentiation. We’ll need both
techniques as we begin to solve <strong>nonlinear equations</strong> and
<strong>optimization problems</strong>. Both subjects are rich, so we’ll touch on
only the basics, but you’ll have tools at your disposal to tackle such
problems in varied applications.</p>
<div class="section" id="Objectives">
<h3>Objectives<a class="headerlink" href="#Objectives" title="Permalink to this headline">¶</a></h3>
<p>By the end of this lesson, you should be able to</p>
<ul class="simple">
<li>Find one or more roots of a one-dimensional, nonlinear equation
<span class="math">\(f(x) = 0\)</span> using the bisection and Newton methods.</li>
<li>Find local extrema of a function <span class="math">\(f(x)\)</span> using the bisection and
Newton methods.</li>
<li>Use <code class="docutils literal"><span class="pre">fsolve</span></code> to solve nonlinear systems.</li>
<li>Use <code class="docutils literal"><span class="pre">minimize</span></code> to solve nonlinear optimization problems.</li>
</ul>
</div>
<div class="section" id="Key-Terms">
<h3>Key Terms<a class="headerlink" href="#Key-Terms" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>nonlinear equation</li>
<li>transcendental equation</li>
<li>graphical solution</li>
<li>bisection method</li>
<li>Newton’s method</li>
<li>quadratic convergence</li>
<li>second-order convergence</li>
<li>order of convergence</li>
<li>secant method</li>
<li>Steffensen’s method</li>
<li>nonlinear systems</li>
<li>Jacobian matrix</li>
<li><code class="docutils literal"><span class="pre">scipy.optimize.fsolve</span></code></li>
<li>optimization</li>
<li>extremum</li>
<li>critical point</li>
<li>objective function</li>
<li><code class="docutils literal"><span class="pre">scipy.optimize.minimize</span></code></li>
</ul>
</div>
</div>
<div class="section" id="Nonlinear-Equations">
<h2>Nonlinear Equations<a class="headerlink" href="#Nonlinear-Equations" title="Permalink to this headline">¶</a></h2>
<p>Linear equations are characterized by <em>linear combinations</em> or the
unknowns. For example, the system of equations for <span class="math">\(x\)</span> and
<span class="math">\(y\)</span></p>
<div class="math">
\[\begin{split}\begin{split}
 ax + by &amp;= 1 \\
 cx + dy &amp;= 2
\end{split}\end{split}\]</div>
<p>is linear because <span class="math">\(x\)</span> and <span class="math">\(y\)</span> appear with only constant
coefficients. There are no <span class="math">\(x^2\)</span> terms, or <span class="math">\(\sin(y)\)</span> terms.
Just multiples of <span class="math">\(x\)</span> and <span class="math">\(y\)</span>. Any deviation from this
pattern results in <strong>nonlinear equations</strong>. For example, quadratic
equation <span class="math">\(ax^2 + bx + c = 0\)</span> is nonlinear, and we know how to find
the <strong>roots</strong> of this equations. A root is the solution <span class="math">\(x\)</span> to any
equation (generally, nonlinear) <span class="math">\(f(x) = 0\)</span>. Our goal now is to
solve such equations using the tools at our disposal.</p>
<div class="section" id="Analytic-Solutions">
<h3>Analytic Solutions<a class="headerlink" href="#Analytic-Solutions" title="Permalink to this headline">¶</a></h3>
<p>In rare cases, nonlinear equations have closed-form solutions (i.e., you
can write it down explicitly). The quadratic equation is one example. In
fact, solutions exist for the general cubic (add a <span class="math">\(x^3\)</span> term) and
quartic (add both <span class="math">\(x^3\)</span> and <span class="math">\(x^4\)</span>). The roots are hideous
(compared to the quadratic equation roots), but they are known.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Use SymPy to find the roots of the cubic equation
<span class="math">\(ax^3 + bx^2 + cx + d = 0\)</span>. Can it also find roots to <em>quintic</em>
equation <span class="math">\(ax^5 + bx^4 + cx^3 + dx^2 + ex + f = 0\)</span>?</p>
<p><em>Solution</em>: The cubic is easy, but SymPy can’t do the quintic. In fact,
the roots to general polynomials of degree 5 and higher cannot be
determined explicity, a fact <a class="reference external" href="https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem">proven by
Abel</a>.</p>
<hr class="docutils" />
<p>For other problems, we often have to have a bit of luck.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Find all values of <span class="math">\(x\)</span> such that
<span class="math">\(\sin(ax) - b = 0\)</span>.</p>
<p><em>Solution</em>: The equation has no solution if <span class="math">\(|b| &gt; 1\)</span> (because
<span class="math">\(-1 \leq \sin(ax) \leq 1\)</span>). If <span class="math">\(|b| \leq 1\)</span>, then
<span class="math">\(x = \frac{\sin^{-1}b}{a} + n\pi\)</span> for
<span class="math">\(n = 0, \pm 1, \pm 2, \ldots\)</span>. Such an equation is called
<strong>transcendental</strong> because it involves a transcendental function (i.e.,
<span class="math">\(\sin(x)\)</span>). Transcendental functions cannot be defined in terms of
polynomial of finite degree; in other words, if one needs an infinitely
long <a class="reference internal" href="ME400_Lecture_20.html"><span class="doc">Taylor series</span></a> to represent the
function, it is transcendental. Transcendental equations almost always
require some form of numerical evaluation.</p>
<p><strong>Exercise</strong>: Solve the nonlinear system of equations <span class="math">\(y - x = 4\)</span>
and <span class="math">\(x^2 + y = 3\)</span>.</p>
</div>
<hr class="docutils" />
<div class="section" id="Graphical-Solutions">
<h3>Graphical Solutions<a class="headerlink" href="#Graphical-Solutions" title="Permalink to this headline">¶</a></h3>
<p>When analytic methods fail, solutions (albeit, approximate) to nonlinear
equations may be found <strong>graphically</strong>. For single equation in
<span class="math">\(x\)</span>, it suffices to plot <span class="math">\(f(x)\)</span> over the range of interest
and identify the roots.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Revisit <span class="math">\(\sin(ax) - b\)</span> for <span class="math">\(a=1\)</span> and
<span class="math">\(b=1/4\)</span> and find all roots between <span class="math">\(x = -5\)</span> and
<span class="math">\(x = 5\)</span>.</p>
<p><em>Solution</em>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>  <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="s1">&#39;r--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/lectures_Root_Finding_4_0.png" src="../_images/lectures_Root_Finding_4_0.png" />
</div>
</div>
<p>Because <code class="docutils literal"><span class="pre">plt.plot</span></code> does not by default draw a line for <span class="math">\(y=0\)</span>, a
dashed, red line is superimposed to provide more obvious intersections
between the function <span class="math">\(f(x)\)</span> and the horizontal axis <span class="math">\(y = 0\)</span>.
It appears (from inspections) that the roots of interest are near -3.5,
0.3, and 2.8. One could certainly zoom in somewhat to improve the
precision of the estimates, but arbitrary precision will require other
techniques.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: A simple, somewhat realistic model of a spherical nuclear
reactor consists of two regions: (1) an inner spherical volume of <em>fuel</em>
of radius <span class="math">\(R\)</span>, in which neutrons induce fission, leading to energy
release and additional neutrons, and (2) an outer, infinitely large
<em>reflector</em> surrounding the fuel, which minimizes the number of neutrons
that escape the fuel. The reactor is <em>critical</em> if the number of
neutrons produced and lost is constant over time. For this simple, two
region model, the condition for criticality is</p>
<div class="math">
\[BR \cot(BR) = 1 - \frac{D_r}{D_f} \left ( \frac{R}{L_r} + 1 \right ) \, ,\]</div>
<p>where <span class="math">\(D_f\)</span>, <span class="math">\(D_r\)</span>, and <span class="math">\(L_r\)</span> are fixed, material
properties of the fuel and reflector. Hence, in order for this
criticality condition to be satisfied, an appropriate value of <span class="math">\(B\)</span>
must be determined. Here, <span class="math">\(B\)</span> is called the <em>buckling</em> and is a
function of several fuel material properties. For <span class="math">\(R=20\)</span>,
<span class="math">\(D_f = 0.9\)</span>, <span class="math">\(D_r = 1.1\)</span>, and <span class="math">\(L_r = 1.7\)</span>, estimate
the first positive value of <span class="math">\(B\)</span> that satisfies the condition.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: The solution of transient heat-conduction problems often
involves a technique called <em>separation of variables</em>. Application of
this technique to an infinite slab of thickness <span class="math">\(2L\)</span> subject to
certain initial and boundary conditions leads to the transcendental
equation</p>
<div class="math">
\[\cot \lambda L = \frac{\lambda L}{hL/k} = \frac{\lambda L}{\text{Bi}} \, ,\]</div>
<p>where <span class="math">\(\lambda\)</span> is a dimensionless, undetermined parameter,
<span class="math">\(h\)</span> is the heat transfer coefficient, <span class="math">\(k\)</span> is the thermal
conductivity, and <span class="math">\(\text{Bi}\)</span> is the <em>Biot number</em>. The Biot
number quantifies how hard it is for heat to flow <em>within</em> a body
relative to how hard it is to flow <em>through the outer surface</em> of the
body. Only for certain values of <span class="math">\(\lambda\)</span> can the equation be
solved. Determine these values graphically by plotting the left-hand and
right-hand sides of the equation as functions of <span class="math">\(\lambda L\)</span>.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Determining-Roots-Numerically">
<h2>Determining Roots Numerically<a class="headerlink" href="#Determining-Roots-Numerically" title="Permalink to this headline">¶</a></h2>
<p>The numerical solution of <span class="math">\(f(x) = 0\)</span> can be challenging since it
requires we know at least a little about the desired solution,
particularly the range in which the root is contained. We’ll explore
three basic schemes for solving <span class="math">\(f(x)\)</span>: the <a class="reference external" href="http://mathworld.wolfram.com/Bisection.html">bisection
method</a>, <a class="reference external" href="http://mathworld.wolfram.com/NewtonsMethod.html">Newton’s
method</a>, and the
secant method.</p>
<div class="section" id="Bisection">
<h3>Bisection<a class="headerlink" href="#Bisection" title="Permalink to this headline">¶</a></h3>
<p>Application of bisection to finding a root of <span class="math">\(f(x)\)</span> requires a
key piece of information: a range <span class="math">\(x \in [L, R]\)</span> in which a
<em>single</em> root lives. The algorithm is actually quite similar to <a class="reference external" href="ME400_Lecture_14">binary
search</a>. A central point <span class="math">\(C\)</span> is selected, and
the function is evaluated at that point. Then, if <span class="math">\(f(C)\)</span> has the
same <em>sign</em> (i.e., <span class="math">\(+\)</span> or <span class="math">\(-\)</span>) as <span class="math">\(f(A)\)</span>, we know that
the root must be between <span class="math">\(C\)</span> and <span class="math">\(B\)</span>. Why? If there is only
one root <span class="math">\(x^*\)</span> between <span class="math">\(L\)</span> and <span class="math">\(R\)</span>, then <span class="math">\(f(x)\)</span>
must have a constant sign for <span class="math">\(x \in [A, x^*)\)</span> and the opposite
sign for <span class="math">\(x \in (x^*, B]\)</span>. If, instead, <span class="math">\(f(x)\)</span> changes signs
between <span class="math">\(x=A\)</span> and <span class="math">\(x=x^*\)</span> then it <em>must</em> cross the <span class="math">\(x\)</span>
axis, at which point there <em>must</em> be a second root.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Write a <code class="docutils literal"><span class="pre">lambda</span></code> function for <span class="math">\(x\)</span> that returns
<code class="docutils literal"><span class="pre">True</span></code> if <span class="math">\(x \geq 0\)</span> and <code class="docutils literal"><span class="pre">False</span></code> otherwise. ***</p>
<p>An important difference between bisection and binary search is that now
the search can require an unlimited number of comparisons because the
search range <span class="math">\([A, B]\)</span> is split in half repeatedly until a root is
<em>converged</em> to within a desired tolerance <span class="math">\(\tau\)</span>. In other words,
roots will very rarely be found <em>exactly</em>; rather, we often must accept
<em>approximate</em> values, as was first introduced in <a class="reference external" href="ME400_Lecture_8">Lecture
8</a>.</p>
<p>In pseudocode, the bisection method can be written as follows (where the
notation from binary search is adopted as closely as is reasonable):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;Bisection method for finding an isolated root of f between a and b&#39;&#39;&#39;</span>
<span class="n">Input</span><span class="p">:</span> <span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">tau</span>

<span class="c1"># Define the left and right boundaries</span>
<span class="n">Set</span> <span class="n">L</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">Set</span> <span class="n">R</span> <span class="o">=</span> <span class="n">b</span>

<span class="c1"># Define the central point</span>
<span class="n">Set</span> <span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>

<span class="c1"># Go until f(C) is close enough to zero (i.e., that</span>
<span class="c1"># C is close enough to the root between a and b</span>
<span class="n">While</span> <span class="o">|</span><span class="n">f</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">|</span> <span class="o">&gt;</span> <span class="n">tau</span>
    <span class="n">If</span> <span class="n">sign</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">C</span><span class="p">))</span> <span class="o">==</span> <span class="n">sign</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">L</span><span class="p">))</span> <span class="n">then</span>
        <span class="c1"># the root must be between C and R</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">C</span>
    <span class="n">Otherwise</span>
        <span class="c1"># the root must be between L and C</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">C</span>
    <span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="n">R</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Output</span><span class="p">:</span> <span class="n">C</span>
</pre></div>
</div>
<p>Application of this algorithm to find the first positive root of
<span class="math">\(\sin(x) - 2/5\)</span> is shown graphically below for the first two
iterations. At each step, the search space is reduced by half,
illustrated by the shrinking highlighted rectangles. By the second
iteration, <span class="math">\(C = 0.375\)</span>, which is visually quite close to the root
of interest <span class="math">\(x = \sin^{-1}(2/5) \approx 0.4115\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">nonlinear_plots</span>
<span class="n">nonlinear_plots</span><span class="o">.</span><span class="n">bisection_root</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/lectures_Root_Finding_10_0.png" src="../_images/lectures_Root_Finding_10_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Exercise</strong>: Apply the bisection algorithm <em>by hand</em> to solve
<span class="math">\(f(x) = x^3 + 2x^2 - 5x - 6 = 0\)</span> for <span class="math">\(x\in [1, 4]\)</span>. Find the
root to within <span class="math">\(\tau = 10^{-1}\)</span>. Write out all values of
<span class="math">\(L\)</span>, <span class="math">\(R\)</span>, <span class="math">\(C\)</span>, and <span class="math">\(f(C)\)</span> for each step.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Implement the bisection algorithm in Python and use it to
solve <span class="math">\(\sin(x) - 2/5\)</span> for <span class="math">\(x \in [0, 1]\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Modify the bisection algorithm to accept a desired number
of iterations <span class="math">\(n\)</span> instead of the tolerance <span class="math">\(\tau\)</span>. Implement
this modified algorithm in Python. Then, show the error in the
approximate root of <span class="math">\(f(x) = \sin(x) - 2/5\)</span> for <span class="math">\(x\in [0, 1]\)</span>
as a function of <span class="math">\(n\)</span>.</p>
</div>
<hr class="docutils" />
<div class="section" id="Newton's-Method">
<h3>Newton’s Method<a class="headerlink" href="#Newton's-Method" title="Permalink to this headline">¶</a></h3>
<p>A more power way to find roots of <span class="math">\(f(x) = 0\)</span> is <a class="reference external" href="http://mathworld.wolfram.com/NewtonsMethod.html">Newton’s
method</a>, sometimes
called the Newton-Raphson method. Like bisection, Newton’s method
produces a sequence of approximations for a root. The values of the
sequence are increasingly close to the root. Unlike bisection, Newton’s
method requires not a range in which a single root lives but an initial
guess for what the root is.</p>
<p>Let the root of interest be <span class="math">\(x_r\)</span>. Assume we have a good way to
guess the root (intuition, a graph, etc.), and call that initial
approximation <span class="math">\(x_0\)</span>. Then, for some <span class="math">\(\Delta\)</span>,
<span class="math">\(x_r = x_0 + \Delta\)</span>,Taylor series provides the following
relationship:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sy</span>
<span class="n">sy</span><span class="o">.</span><span class="n">init_printing</span><span class="p">()</span>
<span class="n">f</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">Delta</span> <span class="o">=</span> <span class="n">sy</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;f x_0 Delta&#39;</span><span class="p">)</span>
<span class="n">x_r</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">Delta</span>
<span class="n">sy</span><span class="o">.</span><span class="n">Eq</span><span class="p">(</span><span class="n">sy</span><span class="o">.</span><span class="n">series</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x_r</span><span class="p">),</span> <span class="n">Delta</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math">
$$f{\left (x_{0} \right )} + \Delta \left. \frac{d}{d \xi_{1}} f{\left (\xi_{1} \right )} \right|_{\substack{ \xi_{1}=x_{0} }} + \mathcal{O}\left(\Delta^{2}\right) = 0$$</div></div>
</div>
<p>Formally, this equation is still exact because
<span class="math">\(\mathcal{O}(\Delta^2)\)</span> captures <em>all</em> terms proportional to
<span class="math">\(\Delta^2\)</span> and higher powers of <span class="math">\(\Delta\)</span>. However, if
<span class="math">\(\Delta\)</span> were small enough that the <span class="math">\(\Delta^2\)</span> terms can be
ignored (i.e., our guess <span class="math">\(x_0\)</span> were close enough to <span class="math">\(x_r\)</span>),
then we’re left with the <em>approximate</em> relationship</p>
<div class="math">
\[f(x_r) = 0 \approx f(x_0) + \Delta f'(x_0) \, ,\]</div>
<p>from which it follows that</p>
<div class="math">
\[\Delta =  -\frac{f(x_0)}{f'(x_0)} \, .\]</div>
<p>We expect <span class="math">\(x_1 = x_1 + \Delta\)</span> to be a <em>better</em> approximation than
<span class="math">\(x_0\)</span>. Moreover, the same process can be applied to determine a
sequence of estimated roots <span class="math">\(x_2\)</span>, <span class="math">\(x_3\)</span>, and so on. This
process is Newton’s method, and is presented in the following
pseudocode:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;Newton&#39;s method for finding the root f given x_0&#39;&#39;&#39;</span>
<span class="n">Input</span><span class="p">:</span> <span class="n">f</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">tau</span>
<span class="n">Set</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x_0</span>
<span class="n">While</span> <span class="o">|</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">|</span> <span class="o">&gt;</span> <span class="n">tau</span> <span class="n">do</span>
   <span class="c1"># Compute the Newton &quot;step&quot;</span>
   <span class="n">Set</span> <span class="n">Delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">fp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   <span class="c1"># Compute the next value of x</span>
   <span class="n">Set</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">Delta</span>
<span class="n">Output</span><span class="p">:</span> <span class="n">x</span>
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Exercise</strong>: Apply Newton’s method <em>manually</em> to solve
<span class="math">\(f(x) = x^3 + 2x^2 - 5x - 6 = 0\)</span> to within <span class="math">\(\tau = 10^{-5}\)</span>.
Use <span class="math">\(x_0 = 3/2\)</span>. Write out <span class="math">\(n\)</span>, <span class="math">\(x_n\)</span>, <span class="math">\(f(x_n)\)</span>,
<span class="math">\(f'(x_n)\)</span> at each step <span class="math">\(n = 0, 1, \ldots\)</span>.</p>
<p><em>Solution</em>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="n">x</span>                       <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>       <span class="n">f</span><span class="s1">&#39;(x)</span>
<span class="mi">0</span> <span class="mf">1.5000000000000000e+00</span> <span class="o">-</span><span class="mf">5.625e+00</span>  <span class="mf">7.750e+00</span>
<span class="mi">1</span> <span class="mf">2.2258064516129030e+00</span>  <span class="mf">3.807e+00</span>  <span class="mf">1.877e+01</span>
<span class="mi">2</span> <span class="mf">2.0229637924064581e+00</span>  <span class="mf">3.487e-01</span>  <span class="mf">1.537e+01</span>
<span class="mi">3</span> <span class="mf">2.0002760690096917e+00</span>  <span class="mf">4.142e-03</span>  <span class="mf">1.500e+01</span>
<span class="mi">4</span> <span class="mf">2.0000000406383567e+00</span>  <span class="mf">6.096e-07</span>  <span class="mf">1.500e+01</span>
<span class="mi">5</span> <span class="mf">2.0000000000000009e+00</span>  <span class="mf">1.421e-14</span>  <span class="mf">1.500e+01</span>
</pre></div>
</div>
<hr class="docutils" />
<p>The exercise above illustrates an important feature of Newton’s method.
Once Newton’s method “get’s going,” the number of correct digits usually
<em>doubles</em> at each step. For example, step 3 got 3 digits right, while
step 4 got 7, and step 5 got 15. That’s pretty quick convergence.</p>
<p>Such convergence is called <strong>quadratic convergence</strong> or <strong>second-order
convergence</strong>. In other words, if the error is <span class="math">\(\epsilon_n\)</span> at
step <span class="math">\(n\)</span>, the error at step <span class="math">\(n+1\)</span> will be
<span class="math">\(\epsilon_{n+1} = a \epsilon_n^2\)</span> for some constant <span class="math">\(a\)</span>.
More generally, the <strong>order of convergence</strong> of a method is the value of
<span class="math">\(p\)</span> for which <span class="math">\(\epsilon_{n+1} = c\epsilon_{n}^p\)</span> for some
constant <span class="math">\(c\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Use the last three values of <span class="math">\(x\)</span> in the last
exercise to estimate the order of convergence of Newton’s method.</p>
<p><em>Solution</em>: Using logarithms, we have
<span class="math">\(\log \epsilon_4 = p \log \epsilon_3 + \log c\)</span> and
<span class="math">\(\log \epsilon_5 = p \log \epsilon_4 + \log c\)</span>. Those are two
equations for the two unknowns <span class="math">\(p\)</span> and <span class="math">\(\log c\)</span>. Now,
recalling what we learned in <a class="reference internal" href="ME400_Lecture_4.html"><span class="doc">Lecture 4</span></a>, this
system is easy to solve:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">e_3</span> <span class="o">=</span> <span class="mf">2.0002760690096917e+00</span><span class="o">-</span><span class="mi">2</span>
<span class="n">e_4</span> <span class="o">=</span> <span class="mf">2.0000000406383567e+00</span><span class="o">-</span><span class="mi">2</span>
<span class="n">e_5</span> <span class="o">=</span> <span class="mf">2.0000000000000009e+00</span><span class="o">-</span><span class="mi">2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">e_3</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">e_4</span><span class="p">),</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">e_4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">e_5</span><span class="p">)])</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math">
$$1.99902739068$$</div></div>
</div>
<p>That’s pretty darn close to 2, and Newton’s method is therefore
confirmed to exhibit second-order convergence (for this problem).</p>
<hr class="docutils" />
<p>Knowledge of a method’s order of convergence is useful when verifying
its implementation. If we saw less than second-order convergence for the
exercise above, then the implementation might be suspect.</p>
</div>
<div class="section" id="Secant-Method">
<h3>Secant Method<a class="headerlink" href="#Secant-Method" title="Permalink to this headline">¶</a></h3>
<p>If we don’t know the derivative of <span class="math">\(f(x)\)</span>, then Newton’s method
can’t be used. Of course, the bisection method is one option, but we can
adapt Newton by leveraging the finite-difference methods from <a class="reference external" href="ME400_Lecture_21.ipynb">Lecture
21</a>. The result is the <strong>secant method</strong>. The
algorithm is nearly identical to Newton’s method, but <span class="math">\(f'(x)\)</span> is
approximated when needed. The classical secant method begins with two
values of <span class="math">\(x\)</span> and the corresponding function values. The finit</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;Secant method for finding the root f given x_0&#39;&#39;&#39;</span>
<span class="n">Input</span><span class="p">:</span> <span class="n">f</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">tau</span>
<span class="n">Set</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x_0</span>
<span class="n">Set</span> <span class="n">x_0</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">tau</span>
<span class="n">While</span> <span class="o">|</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">|</span> <span class="o">&gt;</span> <span class="n">tau</span> <span class="n">do</span>
   <span class="c1"># Approximate the derivative</span>
   <span class="n">Set</span> <span class="n">fp</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">f</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">x_0</span><span class="p">)</span>
   <span class="c1"># Compute the Newton &quot;step&quot;</span>
   <span class="n">Set</span> <span class="n">Delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">fp</span>
   <span class="c1"># Store old x, and compute next value</span>
   <span class="n">Set</span> <span class="n">x_0</span> <span class="o">=</span> <span class="n">x</span>
   <span class="n">Set</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">Delta</span>
<span class="n">Output</span><span class="p">:</span> <span class="n">x</span>
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Exercise</strong>: Apply the secant method <em>manually</em> to solve
<span class="math">\(f(x) = x^3 + 2x^2 - 5x - 6 = 0\)</span> to within <span class="math">\(\tau = 10^{-5}\)</span>.
Use <span class="math">\(x_0 = 3/2\)</span>. Write out <span class="math">\(n\)</span>, <span class="math">\(x_n\)</span>, <span class="math">\(f(x_n)\)</span>,
<span class="math">\(f'(x_n)\)</span> at each step <span class="math">\(n = 0, 1, \ldots\)</span>. How does it
compare to Newton’s method?</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Implement the secant method as a Python function.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Implement a function
<code class="docutils literal"><span class="pre">newton(f,</span> <span class="pre">x_0,</span> <span class="pre">fp=None,</span> <span class="pre">tau=1e-8,</span> <span class="pre">delta=1e-8)</span></code> that applies Newton’s
method when <code class="docutils literal"><span class="pre">fp</span></code> is provided and the secant method if <code class="docutils literal"><span class="pre">fp</span></code> is not
provided. Here, <code class="docutils literal"><span class="pre">delta</span></code> is to be the step used in the
finite-difference approximation to <span class="math">\(f'(x)\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Use the secant method <em>without</em> defining <span class="math">\(f'(x)\)</span> to
solve the following equations: 1. <span class="math">\(\tan(x)/x^2\)</span> for
<span class="math">\(x_0 = 1\)</span>. 2. <span class="math">\(s^2 = 3\)</span> for <span class="math">\(s_0=1.5\)</span>. (What is this
doing?) 3. <span class="math">\(2\cosh(x/4)-x = 0\)</span> with <span class="math">\(x_0 = 4\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Another method that can be used when the derivative is not
available is <a class="reference external" href="https://en.wikipedia.org/wiki/Steffensen%27s_method">Steffensen’s
method</a>.
Steffensen’s method produces a sequence of approximate roots according
to <span class="math">\(x_{n+1} = \frac{f(x_n + f(x_n)) - f(x_n)}{f(x_n)}\)</span>. Try this
method on nonlinear equations from the last exercise. Does it converge
quadratically like Newton’s method?</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Solving-Systems-of-Nonlinear-Equations-Numerically">
<h2>Solving Systems of Nonlinear Equations Numerically<a class="headerlink" href="#Solving-Systems-of-Nonlinear-Equations-Numerically" title="Permalink to this headline">¶</a></h2>
<p>The solution of nonlinear systems is considerably more challenging than
single-variable equations. However, the Newton (and secant) methods
described so far are up to the challenge. A system of nonlinear
equations can be written generically as
<span class="math">\(\mathbf{f}(\mathbf{x}) = \mathbf{0}\)</span>, where the bolded names
indicate vector quantities. Whereas Newton’s method for single-variables
equations requires the derivative <span class="math">\(f'(x)\)</span>, Newton’s method for
systems of equations requires the <strong>jacobian matrix</strong>. For a system of
<span class="math">\(n\)</span> unknows, the jacobian <span class="math">\(\mathbf{J}\)</span> is a square matrix
defined as</p>
<div class="math">
\[\begin{split}  \mathbf{J}(\mathbf{x}) = \begin{bmatrix}
    \frac{\partial f_0}{\partial x_0} &amp; \frac{\partial f_1}{\partial x_0} &amp; \ldots &amp; \frac{\partial f_{n-1}}{\partial x_0} \\
    \frac{\partial f_0}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_1} &amp; \ldots &amp; \frac{\partial f_{n-1}}{\partial x_1} \\
         &amp;     &amp;  \ddots &amp;  \\
    \frac{\partial f_0}{\partial x_{n-1}} &amp; \frac{\partial f_1}{\partial x_{n-1}} &amp; \ldots &amp; \frac{\partial f_{n-1}}{\partial x_{n-1}}
\end{bmatrix}\end{split}\]</div>
<p>where <span class="math">\(x_i\)</span> indicates the <span class="math">\(i\)</span>th unknown (or element
<span class="math">\(i\)</span> of <span class="math">\(\mathbf{x}\)</span>).</p>
<p>Then, Newton’s method leads to the sequence</p>
<div class="math">
\[\mathbf{x}_{n+1} = \mathbf{x}_{n} - \mathbf{J}^{-1}(\mathbf{x}_n) \mathbf{f}(\mathbf{x}_n) \, .\]</div>
<p>Here, <span class="math">\(\mathbf{f}(\mathbf{x}_n)\)</span> and
<span class="math">\(\mathbf{J}(\mathbf{x}_n)\)</span> indicate the function and its jacobian
are evalaluated at <span class="math">\(\mathbf{x}_n\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Consider the nonlinear system of equations <span class="math">\(x-y = 4\)</span>
and <span class="math">\(x^2 + y = -3\)</span>. Derive the jacobian matrix, and apply one step
of Newton’s method using <span class="math">\(x_0=1/2\)</span> and <span class="math">\(y_0=-3\)</span>. (<em>Hint</em>:
Check your work by defining <code class="docutils literal"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">sy.Matrix([x-y-4,</span>&#160; <span class="pre">x**2+y+3])</span></code> and
<code class="docutils literal"><span class="pre">J</span> <span class="pre">=</span> <span class="pre">f.jacobian([x,</span> <span class="pre">y])</span></code>. Feel free to dig in a bit and see how
matrix-vector multiplication works in SymPy.)</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: What’s the Jacobian matrix for the <em>linear</em> system
<span class="math">\(ax+by = 1\)</span> and <span class="math">\(cx+dy=2\)</span>? How many Newton iterations are
required to solve the system for <em>any</em> initial values <span class="math">\(x_0\)</span> and
<span class="math">\(y_0\)</span>?</p>
<hr class="docutils" />
<div class="section" id="scipy.optimize.fsolve">
<h3><code class="docutils literal"><span class="pre">scipy.optimize.fsolve</span></code><a class="headerlink" href="#scipy.optimize.fsolve" title="Permalink to this headline">¶</a></h3>
<p>Although implementation of a Newton (or secant) method for systems would
be possible using NumPy, it is more practical to use the tools included
in SciPy. In particular, the <code class="docutils literal"><span class="pre">scipy.optimize.fsolve</span></code> function
implements a method that combines Newton’s method with some other
techniques applied when Newton’s method cannot reliably converge (e.g.,
what happens when <span class="math">\(f'(x)\)</span> vanishes near the root of interest?).</p>
<p>The signature (from <code class="docutils literal"><span class="pre">help(fsolve)</span></code>) is</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">fsolve</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">fprime</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">col_deriv</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xtol</span><span class="o">=</span><span class="mf">1.49012e-08</span><span class="p">,</span> <span class="n">maxfev</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">band</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">epsfcn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">diag</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p>The arguments of interest here are <code class="docutils literal"><span class="pre">func</span></code>, <code class="docutils literal"><span class="pre">x0</span></code>, <code class="docutils literal"><span class="pre">args</span></code>, and
<code class="docutils literal"><span class="pre">fprime</span></code>; refer to the documentation for more on the the other
arguments. From <code class="docutils literal"><span class="pre">help(fsolve)</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>func : callable ``f(x, *args)``
    A function that takes at least one (possibly vector) argument.
x0 : ndarray
    The starting estimate for the roots of ``func(x) = 0``.
args : tuple, optional
    Any extra arguments to `func`.
fprime : callable(x), optional
    A function to compute the Jacobian of `func` with derivatives
</pre></div>
</div>
<p>Hence, <code class="docutils literal"><span class="pre">func</span></code> represents our nonlinear system function
<span class="math">\(\mathbf{f}(\mathbf{x})\)</span>, and <code class="docutils literal"><span class="pre">args</span></code> represents any values
needed to define what <span class="math">\(\mathbf{f}(\mathbf{x})\)</span> does. The initial
guess is <code class="docutils literal"><span class="pre">x0</span></code>. If available, <code class="docutils literal"><span class="pre">fprime</span></code> should compute
<span class="math">\(\mathbf{J}(\mathbf{x})\)</span>; if not provided, <code class="docutils literal"><span class="pre">fsolve</span></code> approximates
the Jacobian using a forward-difference approximation.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Solve the nonlinear system of equations <span class="math">\(x-y = 4\)</span>
and <span class="math">\(x^2 + y = -3\)</span> using <code class="docutils literal"><span class="pre">fsolve</span></code> <span class="math">\(x_0=1/2\)</span> and
<span class="math">\(y_0=-3\)</span>.</p>
<p><em>Solution</em>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fsolve</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">z</span> <span class="c1"># unpack z</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">y</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>

<span class="n">z0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">]</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">z0</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math">
$$\left ( 0.61803398875, \quad -3.38196601125\right )$$</div></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Finding-Extrema">
<h2>Finding Extrema<a class="headerlink" href="#Finding-Extrema" title="Permalink to this headline">¶</a></h2>
<p>One of the great applications of differentiation is its ability to
identify the <em>critical points</em> of a function <span class="math">\(f(x)\)</span>, which include
its minima and maxima. If <span class="math">\(f(x)\)</span> represents some quantity of
interest, perhaps the cost of materials for some component or the
signal-to-noise ratio of some sensor. If we want to mininimize those
costs or maximize those ratios, we need to use <em>optimization</em>. Although
optimization problems and the techniques to solve them are quite
diverse, we will stick to 1-D problems in which the <em>objective function</em>
to be minimized or maximized is continuous (as opposed to discrete).</p>
<p>You’ve had calculus (and we’ve reviewed some its topics). Hence, you
might recall that a function <span class="math">\(f(x)\)</span> exhibits an <strong>extremum</strong>,
i.e., a <strong>minimum</strong> or <strong>maximum</strong>, at any point <span class="math">\(x\)</span> for which
<span class="math">\(f'(x)\)</span> is zero and <span class="math">\(f''(x)\)</span> is nonzero. When <span class="math">\(f'(x)\)</span>
<em>and</em> <span class="math">\(f''(x)\)</span> vanish, the point is often called a <strong>saddle
point</strong>, though that term is more meaningful in multiple dimensions.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Given some fencing of <em>fixed</em> length <code class="docutils literal"><span class="pre">L</span></code>, what is the
largest area that fencing can enclose if arranged in a rectangle of
sides <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code>?</p>
<p><em>Solution</em>:</p>
<p>Here’s the problem. We want to maximize <span class="math">\(A = ab\)</span> where
<span class="math">\(2a+2b = L\)</span> or <span class="math">\(b = L/2 - a\)</span>. We know <span class="math">\(L\)</span> and
<span class="math">\(b\)</span> depends on <span class="math">\(a\)</span>, so there is just one free parameter
(i.e., we’re in 1-D where we’ll stay throughout). Note that <span class="math">\(a\)</span>
(and <span class="math">\(b\)</span>) can range from 0 to <span class="math">\(L/2\)</span>.</p>
<p>Formally, we see a solution to</p>
<div class="math">
\[\max_{a \in [0,\, L/2]} a\left (\frac{L}{2}-a \right)\]</div>
<p>which reads “find the value of <span class="math">\(a\)</span> in the range <span class="math">\([0, L/2]\)</span>
that maximizes the quantity <span class="math">\(f(a) = a(L/2-a)\)</span>. Here, <span class="math">\(f(a)\)</span>
is the <strong>objective function</strong>.</p>
<p>Differentiation of <span class="math">\(f(a)\)</span> gives</p>
<div class="math">
\[f'(a) = L/2 - 2a\]</div>
<p>which, when set to zero, requires that <span class="math">\(a = L/4\)</span>. Consequently,
<span class="math">\(b = L/2-a = L/4 = a\)</span>. That is to say, our fence must form a
square to maximize the area enclosed.</p>
</div>
<hr class="docutils" />
<div class="section" id="The-Connection-To-Nonlinear-Functions">
<h2>The Connection To Nonlinear Functions<a class="headerlink" href="#The-Connection-To-Nonlinear-Functions" title="Permalink to this headline">¶</a></h2>
<p>As the fence exercise illustrates, if we can write down the derivative
and explicitly find the point at which it vanishes, our problem is
solved. That is rarely the case. Often, the functions of interest have
complicated derivatives that make <span class="math">\(f'(x) = 0\)</span> a nonlinear
equation. We generally can’t solve that problem directly. In many cases,
we don’t even have <span class="math">\(f'(x)\)</span>, and at best, we can approximate it
numerically using finite differences.</p>
<p>Further complicating matters is that even if we can solve
<span class="math">\(f'(x)=0\)</span>, the result might not be an extremum (consider
<span class="math">\(f(x)=x^3\)</span> and the zeros of its derivative <span class="math">\(3x^2\)</span>), and it
might not be unique.</p>
<p>Consider the following example (for <span class="math">\(f(x) = \sin(x^22)-3)^2\)</span>):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">nonlinear_plots</span><span class="o">.</span><span class="n">extrema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/lectures_Root_Finding_31_0.png" src="../_images/lectures_Root_Finding_31_0.png" />
</div>
</div>
<p>Of the three roots, two correspond to minima—but the left one (blue
circle) is greater than the right one (red square), so is it really a
minimum? <em>Yes</em>, if we make the distinction between <em>local</em> and <em>global</em>
minima. For this problem, the right minimum is the <em>global</em> minimum,
while the central root (green star) represents a local maximum
(<span class="math">\(f(x)\)</span> is <em>unbounded</em>, i.e., there is no value <span class="math">\(M &lt; \infty\)</span>
such that <span class="math">\(|f(x)| &lt; M\)</span> for all possible values of <span class="math">\(x\)</span>).
Given the choice, a global optimum is usualy preferred, but for many
cases, we’re at best guaranteed a local minimum. There are techniques to
increase our chances of finding a global optimum, but that’s outside the
present scope!</p>
<div class="section" id="When-the-Derivative-is-Available">
<h3>When the Derivative is Available<a class="headerlink" href="#When-the-Derivative-is-Available" title="Permalink to this headline">¶</a></h3>
<p>If we have <span class="math">\(f(x)\)</span> and can evaluated <span class="math">\(f'(x)\)</span>, then either
Newton’s method or the secant method can be applied to
<span class="math">\(g(x)=f'(x) = 0\)</span>. (The same goes for multi-variable problems). In
fact, this approach (among others) in built into
<code class="docutils literal"><span class="pre">scipy.optimize.minimize</span></code>, which the reader should investigate.</p>
</div>
<div class="section" id="When-the-Derivative-is-Unavailable">
<h3>When the Derivative is Unavailable<a class="headerlink" href="#When-the-Derivative-is-Unavailable" title="Permalink to this headline">¶</a></h3>
<p>If we had <span class="math">\(f'(x)\)</span>, we could apply Newton’s method to
<span class="math">\(g(x) = f'(x) = 0\)</span>. Assuming we don’t, how to proceed? One option
is to adapt the bisection method. Now, the search is not based on the
change of the sign of <span class="math">\(f(x)\)</span> but rather it’s magnitude relative to
the left and right points. Again, we have to have isolated our (single)
target value in some finite range, which may be no easy task (plotting
helps).</p>
</div>
</div>
<div class="section" id="Further-Reading">
<h2>Further Reading<a class="headerlink" href="#Further-Reading" title="Permalink to this headline">¶</a></h2>
<p>Checkout out the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.html">SciPy
documentation</a>
on optimization and root finding.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Root Finding</a><ul>
<li><a class="reference internal" href="#Overview,-Objectives,-and-Key-Terms">Overview, Objectives, and Key Terms</a><ul>
<li><a class="reference internal" href="#Objectives">Objectives</a></li>
<li><a class="reference internal" href="#Key-Terms">Key Terms</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Nonlinear-Equations">Nonlinear Equations</a><ul>
<li><a class="reference internal" href="#Analytic-Solutions">Analytic Solutions</a></li>
<li><a class="reference internal" href="#Graphical-Solutions">Graphical Solutions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Determining-Roots-Numerically">Determining Roots Numerically</a><ul>
<li><a class="reference internal" href="#Bisection">Bisection</a></li>
<li><a class="reference internal" href="#Newton's-Method">Newton’s Method</a></li>
<li><a class="reference internal" href="#Secant-Method">Secant Method</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Solving-Systems-of-Nonlinear-Equations-Numerically">Solving Systems of Nonlinear Equations Numerically</a><ul>
<li><a class="reference internal" href="#scipy.optimize.fsolve"><code class="docutils literal"><span class="pre">scipy.optimize.fsolve</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#Finding-Extrema">Finding Extrema</a></li>
<li><a class="reference internal" href="#The-Connection-To-Nonlinear-Functions">The Connection To Nonlinear Functions</a><ul>
<li><a class="reference internal" href="#When-the-Derivative-is-Available">When the Derivative is Available</a></li>
<li><a class="reference internal" href="#When-the-Derivative-is-Unavailable">When the Derivative is Unavailable</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Further-Reading">Further Reading</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="Linear_Systems.html" title="previous chapter">Linear Systems</a></li>
      <li>Next: <a href="Optimization.html" title="next chapter">Optimization</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/lectures/Root_Finding.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Jeremy Roberts.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/lectures/Root_Finding.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>