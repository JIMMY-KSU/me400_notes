
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Lecture 21 - Numerical Differentiation &#8212; ME 400 Course Notes Fall 2017 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     'Fall 2017',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Lecture 20 - Taylor Series and the Root of Numerical Methods" href="ME400_Lecture_20.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="section" id="Lecture-21---Numerical-Differentiation">
<h1>Lecture 21 - Numerical Differentiation<a class="headerlink" href="#Lecture-21---Numerical-Differentiation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Overview,-Objectives,-and-Key-Terms">
<h2>Overview, Objectives, and Key Terms<a class="headerlink" href="#Overview,-Objectives,-and-Key-Terms" title="Permalink to this headline">¶</a></h2>
<p>In <a class="reference internal" href="ME400_Lecture_20.html"><span class="doc">Lecture 20</span></a>, Taylor series were reviewed,
and SymPy was used to define and study such series. A key idea
introduced was that a <em>truncated</em> Taylor series expansion of
<span class="math">\(f(x)\)</span> about <span class="math">\(x_0\)</span> is (1) accurate near the point
<span class="math">\(x_0\)</span> and (2) made better by including additional terms of the
full series. In this lesson, such truncated series are used to define
<strong>finite difference</strong> approximations for derivatives. Although good for
some applications by themselves, finite-difference approximations are
critical for solving differential equations numerically, a topic to be
covered in several lectures.</p>
<div class="section" id="Objectives">
<h3>Objectives<a class="headerlink" href="#Objectives" title="Permalink to this headline">¶</a></h3>
<p>By the end of this lesson, you should be able to</p>
<ul class="simple">
<li>Derive finite-difference approximations for first- and second-order
derivatives using Taylor series.</li>
<li>Apply SymPy to compute finite-difference approximations of arbitrary
order for any derivative.</li>
<li>Numerically/graphically/symbolically demonstrate that the error of an
<span class="math">\(n\)</span>th-order approximation as <span class="math">\(\Delta \to 0\)</span> exhibits
the right behavior.</li>
</ul>
</div>
<div class="section" id="Key-Terms">
<h3>Key Terms<a class="headerlink" href="#Key-Terms" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>finite difference</li>
<li>forward difference</li>
<li>backward difference</li>
<li>central difference</li>
<li>truncation error</li>
<li>first-order approximation</li>
<li>second-order approximation</li>
<li><span class="math">\(n\)</span>th-order approximation</li>
</ul>
</div>
</div>
<div class="section" id="If,-in-the-beginning,--didn't-go-to-0...">
<h2>If, in the beginning, <span class="math">\(h\)</span> didn’t go to 0…<a class="headerlink" href="#If,-in-the-beginning,--didn't-go-to-0..." title="Permalink to this headline">¶</a></h2>
<p>Recall from <a class="reference internal" href="ME400_Lecture_19.html"><span class="doc">Lecture 19</span></a> that the derivative
of <span class="math">\(f(x)\)</span> is</p>
<div class="math">
\[\frac{df}{dx} = \lim_{\Delta \to 0} \frac{f(x+\Delta)-f(x)}{\Delta} \, .\]</div>
<p>Here, <span class="math">\(h\)</span> (the ubiquitous “step” used in calculus books around the
world) is swapped for <span class="math">\(\Delta\)</span> (a better symbol that represents
“small change”). What if that limit is not taken and, instead, a “small”
value of <span class="math">\(\Delta\)</span> is used? The result is our first
<strong>finite-difference</strong> approximation, the <strong>forward difference</strong>:</p>
<div class="math">
\[f'(x) \approx  \frac{f(x+\Delta)-f(x)}{\Delta} \, .\]</div>
<p>This is called the <em>forward</em> difference approximation because
<span class="math">\(f'(x)\)</span> depends on information (1) at point <span class="math">\(x\)</span> and (2) to
the right (or forward) of <span class="math">\(x\)</span> at <span class="math">\(x+\Delta\)</span>. Intuition
suggests that this approximation improves with smaller <span class="math">\(\Delta\)</span>.</p>
<p>An equally valid approximation is the <strong>backward difference</strong>:</p>
<div class="math">
\[f'(x) \approx  \frac{f(x)-f(x-\Delta)}{\Delta} \, .\]</div>
<hr class="docutils" />
<p><strong>Exercise</strong>: Use the forward-difference approximation to approximate
the derivative of <span class="math">\(e^x\)</span> at <span class="math">\(x = 1\)</span> for
<span class="math">\(\Delta = 1, 0.1, 0.01, and 0.001\)</span> and plot the error as a
function of <span class="math">\(\Delta\)</span>.</p>
<p><em>Solution</em>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">fp_ref</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># fp for &quot;f prime&quot;</span>
<span class="n">Delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">fp_appx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Delta</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Delta</span><span class="p">)):</span>
    <span class="n">fp_appx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">Delta</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="n">Delta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">Delta</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fp_appx</span><span class="o">-</span><span class="n">fp_ref</span><span class="p">),</span> <span class="s1">&#39;k-o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$\Delta$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$|f_{appx}&#39;(x)-f&#39;(x)|$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/lectures_ME400_Lecture_21_3_0.png" src="../_images/lectures_ME400_Lecture_21_3_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Exercise</strong>: Repeat the previous exercise but use the <em>backward</em>
difference. Do you observe any difference?</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Apply the <em>central</em> difference to the function
<span class="math">\(f(x) = \sin(2x - 0.17) + 0.3 \cos(3.4x + 0.1)\)</span> at
<span class="math">\(x = 0.5\)</span>. Plot the error for
<span class="math">\(\Delta = 10^{-1}, 10^{-2}, \ldots, 10^{-7}\)</span>.</p>
</div>
<hr class="docutils" />
<div class="section" id="Back-to-Order">
<h2>Back to Order<a class="headerlink" href="#Back-to-Order" title="Permalink to this headline">¶</a></h2>
<p>The solved exercise above suggests that the forward-difference
approximation yields a better approximation as <span class="math">\(\Delta\)</span> grows
smaller, but <em>how much better</em>? To answer this, we revisit the Taylor
series for <span class="math">\(f(x+\Delta)\)</span> about the point <span class="math">\(x\)</span>:</p>
<div class="math">
\[f(x+\Delta) = f(x) + f'(x)\Delta + \frac{1}{2}f''(x)\Delta^2 + \mathcal{O}(\Delta^3) \, .\]</div>
<p>By isolating <span class="math">\(f'(x)\)</span> on one side, we have</p>
<div class="math">
\[\begin{split}\begin{split}
  f'(x) &amp;= \frac{f(x+\Delta) - f(x)}{\Delta} - \frac{1}{2}f''(x)\Delta + \mathcal{O}(\Delta^2) \\
        &amp;= \frac{f(x+\Delta) - f(x)}{\Delta} + \mathcal{O}(\Delta) \\
\end{split}\end{split}\]</div>
<p>In other words, the forward difference leaves out terms proportional to
<span class="math">\(\Delta\)</span> and higher powers of <span class="math">\(\Delta\)</span>. Moreover, as
<span class="math">\(\Delta\)</span> shrinks, <span class="math">\(\Delta \gg \Delta^p\)</span> for <span class="math">\(p &gt; 1\)</span>.
The terms left out represent the <strong>truncation error</strong>, and because this
error goes as <span class="math">\(\Delta^1\)</span> for small <span class="math">\(\Delta\)</span>, the
forward-difference approximation is a <strong>first-order approximation</strong>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Show that the backward-difference approximation is also
first order.</p>
<hr class="docutils" />
<p>Can we do better than first order? It turns out that we can. Consider
the following Taylor series:</p>
<div class="math">
\[f(x-\Delta) = f(x) - f'(x)\Delta + \frac{1}{2}f''(x)\Delta^2 + \mathcal{O}(\Delta^3) \, .\]</div>
<p>Subtraction of this series from the one above for <span class="math">\(f(x+\Delta)\)</span>
leads to</p>
<div class="math">
\[f(x+\Delta)-f(x-\Delta) = 2 f'(x)\Delta + \mathcal{O}(\Delta^3) \, ,\]</div>
<p>or</p>
<div class="math">
\[f'(x) = \frac{f(x+\Delta)-f(x-\Delta)}{2\Delta} + \mathcal{O}(\Delta^2) \, .\]</div>
<p>This latter approximation for <span class="math">\(f'(x)\)</span> is a <strong>central difference</strong>
and is a <strong>second-order approximation</strong> because <span class="math">\(\Delta\)</span> is raised
to the second power.</p>
<blockquote>
<div><strong>Note</strong>: Forward and backward differences yield first-order
approximations to <span class="math">\(f'(x)\)</span>, while the central difference yields
a second-order approximation for <span class="math">\(f'(x)\)</span>.</div></blockquote>
<hr class="docutils" />
<p><strong>Exercise</strong>: Consider the Taylor series for <span class="math">\(f(x-\Delta)\)</span>,
<span class="math">\(f(x+\Delta)\)</span>, <span class="math">\(f(x-2\Delta)\)</span>, and <span class="math">\(f(x+2\Delta)\)</span>. Try
to develop a fourth-order approximation for <span class="math">\(f'(x)\)</span> that involves
these four values of <span class="math">\(f\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Consider a function <span class="math">\(f(x)\)</span> for which you are given
values only at <span class="math">\(x = i\Delta\)</span> for <span class="math">\(i = 0, 1, 2, \ldots\)</span> for
small <span class="math">\(\Delta\)</span>. Suppose that some application requires that you
evaluate <span class="math">\(f(x)\)</span> at some middle point <span class="math">\((i+1/2)\Delta\)</span>. Of
course, the natural thing to do is <em>average</em> the two adjacent values at
<span class="math">\(i\Delta\)</span> and <span class="math">\((i+1)\Delta\)</span>. What order is this <em>averaging</em>
approximation?</p>
</div>
<hr class="docutils" />
<div class="section" id="Approximating-the-Second-Derivative">
<h2>Approximating the Second Derivative<a class="headerlink" href="#Approximating-the-Second-Derivative" title="Permalink to this headline">¶</a></h2>
<p>So far, the finite differences developed represent approximations to the
<em>first</em> derivative, <span class="math">\(f'(x)\)</span>. Approximations for the <em>second</em>
derivative can be derived in a similar fashion. Consider again the
Taylor series for <span class="math">\(f(x+\Delta)\)</span> and <span class="math">\(f(x-\Delta)\)</span>. Whereas
these series were <em>subtracted</em> to yield the central-difference
approximation for <span class="math">\(f'(x)\)</span>, they can insteady be <em>added</em> to yield
the following:</p>
<div class="math">
\[f(x+\Delta)+f(x-\Delta) = 2f(x) +  f''(x)\Delta^2 + \mathcal{O}(\Delta^4) \, ,\]</div>
<p>where both the <span class="math">\(f'\)</span> and <span class="math">\(f'''\)</span> terms cancel. By isolating
<span class="math">\(f''(x)\)</span>, we have</p>
<div class="math">
\[f''(x) = \frac{f(x+\Delta)+-2f(x)+f(x-\Delta)}{\Delta^2} + \mathcal{O}(\Delta^2) \, ,\]</div>
<p>which is the central-difference approximation for the second derivative.
Like the central-difference approximation for the first derivative, the
truncation error is second order.</p>
<p>By the way, how can we establish order? In fact, <a class="reference internal" href="ME400_Lecture_14.html"><span class="doc">Lecture
14</span></a> and <a class="reference internal" href="ME400_Lecture_15.html"><span class="doc">Lecture
15</span></a> introduced numerical experiments for
searching and sorting to establish an algorithm’s order. Although
“order” means something different here, the technique is similar: we
test the approximation for different values of <span class="math">\(\Delta\)</span> and see
whether the error goes as <span class="math">\(\Delta\)</span> or <span class="math">\(\Delta^2\)</span> or
something else entirely. By “see”, I mean literally: use a graphic!</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Confirm graphically that the central-difference
approximation for the second derivative is, in fact, second order. Use
<span class="math">\(f(x) = e^x\)</span> for demonstration.</p>
<p><em>Solution</em>: I set us up for success with the last solved exercise, which
is adapted here.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">fpp_ref</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># fpp for &quot;f prime prime&quot;</span>
<span class="n">Delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">fpp_appx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Delta</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Delta</span><span class="p">)):</span>
    <span class="n">fpp_appx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">Delta</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">Delta</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span><span class="o">/</span><span class="n">Delta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">Delta</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fpp_appx</span><span class="o">-</span><span class="n">fpp_ref</span><span class="p">),</span> <span class="s1">&#39;k-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$|f_{appx}&#39;&#39;(x)-f&#39;&#39;(x)|$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">Delta</span><span class="p">,</span> <span class="n">Delta</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathcal{O}(\Delta)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">Delta</span><span class="p">,</span> <span class="n">Delta</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;g--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathcal{O}(\Delta^2)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$\Delta$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;The error follows $\Delta^2$, so confirmed!&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/lectures_ME400_Lecture_21_8_0.png" src="../_images/lectures_ME400_Lecture_21_8_0.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Finite-Difference-Approximations-of-Arbitrary-Order">
<h2>Finite-Difference Approximations of Arbitrary Order<a class="headerlink" href="#Finite-Difference-Approximations-of-Arbitrary-Order" title="Permalink to this headline">¶</a></h2>
<p>The finite-difference approximations explored were identified pretty
easily by manipulating the Taylor series of a function. Approximations
that are higher order or that can be used for higher derivatives are
somewhat more challenging to develop.</p>
<div class="section" id="Simple-Rules">
<h3>Simple Rules<a class="headerlink" href="#Simple-Rules" title="Permalink to this headline">¶</a></h3>
<p>Generally, approximations that use values of <span class="math">\(f\)</span> at more values of
<span class="math">\(x\)</span> (e.g., <span class="math">\(x-\Delta\)</span> and <span class="math">\(x+\Delta\)</span>) are better than
those that use fewer.</p>
<p><em>A more specific rule-of-thumb</em>: an <span class="math">\(n\)</span>th-order approximation
for the <span class="math">\(m\)</span>th derivative requires that <span class="math">\(f\)</span> be evaluated at
<span class="math">\(n+m-1\)</span> evenly-spaced <span class="math">\(x\)</span> values if those values are
symmetric about <span class="math">\(x\)</span> (e.g., <span class="math">\(x-\Delta\)</span> and <span class="math">\(x+\Delta\)</span>
as used for the central difference) or <span class="math">\(n+m\)</span> points, if the points
are not symmetric about <span class="math">\(x\)</span> (e.g., <span class="math">\(x-\Delta\)</span> and <span class="math">\(x\)</span>
as used for the backward difference).</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Does the backward-difference approximation for
<span class="math">\(df/dx\)</span> follow this rule?</p>
<p><em>Solution</em>: The backward-difference approximation for the first
derivative (<span class="math">\(m=1\)</span>) is first order (<span class="math">\(n=1\)</span>). The points are
not symmetric about <span class="math">\(x\)</span>. Hence, the rule requires <span class="math">\(m+n = 2\)</span>
points, consistent with the approximation.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Does the forward-difference approximation for
<span class="math">\(df/dx\)</span> follow this rule?</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Does the central-difference approximation for
<span class="math">\(df/dx\)</span> follow this rule?</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Does the central-difference approximation for
<span class="math">\(d^2f/dx^2\)</span> follow this rule?</p>
</div>
<hr class="docutils" />
<div class="section" id="Developing-New-Schemes">
<h3>Developing New Schemes<a class="headerlink" href="#Developing-New-Schemes" title="Permalink to this headline">¶</a></h3>
<p>Finite-difference schemes of arbitrary order can always be determined
directly from Taylor series, but the work involved can be tedious and
requires intuition that one builds over time working with such schemes.
Hence, to develop such approximations from scratch is outside our scope,
but we can turn again to SymPy for some help using its
<code class="docutils literal"><span class="pre">as_finite_difference</span></code> function. For example, we can recreate our
forward difference scheme via</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">sy</span>
<span class="n">sy</span><span class="o">.</span><span class="n">init_printing</span><span class="p">()</span>
<span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">Delta</span> <span class="o">=</span> <span class="n">sy</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;f x Delta&#39;</span><span class="p">)</span>
<span class="n">fp</span> <span class="o">=</span> <span class="n">sy</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
<span class="n">fp</span><span class="o">.</span><span class="n">as_finite_difference</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">+</span><span class="n">Delta</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math">
$$- \frac{1}{\Delta} f{\left (x \right )} + \frac{1}{\Delta} f{\left (\Delta + x \right )}$$</div></div>
</div>
<p>The syntax is straightforward. Given an expression <code class="docutils literal"><span class="pre">expr</span></code> that
represents a derivative (e.g., <code class="docutils literal"><span class="pre">sy.diff(f(x),</span> <span class="pre">x)</span></code>), then
<code class="docutils literal"><span class="pre">expr.as_finite_difference(list)</span></code> accepts a <code class="docutils literal"><span class="pre">list</span></code> of symbolic
points. To follow our development above, these points should be some
subsequence of <span class="math">\(x \pm i\Delta\)</span> where
<span class="math">\(i = \ldots, -2, -1, 0, 1, 2, \ldots\)</span>.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Apply the rule-of-thumb to determine a third-order
definition for <span class="math">\(f'(x)\)</span> and <em>verify the order</em> numerically. (Hint:
if the method is second order, that means it goes as <span class="math">\(\Delta^2\)</span>.
Hence, a reduction of <span class="math">\(\Delta\)</span> by two should lead to what
reduction in the error?)</p>
<p><em>Solution</em>: A quick attempt will show that the points <span class="math">\(x-\Delta\)</span>,
<span class="math">\(x\)</span>, and <span class="math">\(x+\Delta\)</span> do not work. Can you work out why using
the Taylor series from above?. Alternatively, choose a fourth point
<span class="math">\(x+2\Delta\)</span>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">expr</span> <span class="o">=</span> <span class="n">fp</span><span class="o">.</span><span class="n">as_finite_difference</span><span class="p">([</span><span class="n">x</span><span class="o">-</span><span class="n">Delta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">+</span><span class="n">Delta</span><span class="p">,</span> <span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">Delta</span><span class="p">])</span><span class="o">.</span><span class="n">simplify</span><span class="p">()</span>
<span class="n">expr</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math">
$$\frac{1}{\Delta} \left(- \frac{1}{2} f{\left (x \right )} - \frac{1}{3} f{\left (- \Delta + x \right )} + f{\left (\Delta + x \right )} - \frac{1}{6} f{\left (2 \Delta + x \right )}\right)$$</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">exp</span><span class="p">,</span> <span class="n">log10</span>
<span class="n">ref</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">err</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">ref</span> <span class="o">-</span> <span class="p">(</span><span class="o">-</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">d</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span><span class="o">-</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">d</span><span class="p">)</span><span class="o">-</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">d</span><span class="p">)</span><span class="o">/</span><span class="mi">6</span><span class="p">)</span><span class="o">/</span><span class="n">d</span><span class="p">)</span>
<span class="n">err_0_100</span> <span class="o">=</span> <span class="n">err</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">err_0_010</span> <span class="o">=</span> <span class="n">err</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">err_0_001</span> <span class="o">=</span> <span class="n">err</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="s2">&quot;{:.3e} {:.3e} {:.3e}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">err_0_100</span><span class="p">,</span> <span class="n">err_0_010</span><span class="p">,</span> <span class="n">err_0_001</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[5]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&#39;2.360e-04 2.274e-07 2.271e-10&#39;
</pre></div>
</div>
</div>
<p>Reduction of <span class="math">\(\Delta\)</span> by a a factor of 10 leads to a reduction in
the error of approximately 1000 (i.e., <span class="math">\(10^3\)</span>), exactly as
expected if the error were proportional to <span class="math">\(\Delta^3\)</span>. To confirm,
check the logarithm of each ratio:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">log10</span><span class="p">(</span><span class="n">err_0_100</span><span class="o">/</span><span class="n">err_0_010</span><span class="p">),</span> <span class="n">log10</span><span class="p">(</span><span class="n">err_0_010</span><span class="o">/</span><span class="n">err_0_001</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math">
$$\left ( 3.0160082311842182, \quad 3.0005824517909137\right )$$</div></div>
</div>
<p>These values are very close to three, therefore confirming the third
order expected. Note that the second ratio is even closer to 3 than the
first. Recall, the notion of order (here, <span class="math">\(\mathcal{O}(\Delta^3)\)</span>)
is defined specifically as <span class="math">\(\Delta\)</span> goes to zero. Hence, only as
<span class="math">\(\Delta\)</span> becomes very small will the <span class="math">\(\Delta^3\)</span> terms
dominate, making any other contributions to the error appear to be
negligible.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Use <code class="docutils literal"><span class="pre">sympy.series</span></code> to show that that the
finite-difference scheme
<span class="math">\(\frac{1}{\Delta} \left(- \frac{1}{2} f{\left (x \right )} - \frac{1}{3} f{\left (- \Delta + x \right )} + f{\left (\Delta + x \right )} - \frac{1}{6} f{\left (2 \Delta + x \right )}\right)\)</span>
is, in fact, third order.</p>
<hr class="docutils" />
<p><strong>Exercise</strong>: Develop a second-order finite-difference approximation for
<span class="math">\(d^3 f/dx^3\)</span> using just four points and confirm its order
numerically, graphically, or symbolically.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Further-Reading">
<h2>Further Reading<a class="headerlink" href="#Further-Reading" title="Permalink to this headline">¶</a></h2>
<p>None for now.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Lecture 21 - Numerical Differentiation</a><ul>
<li><a class="reference internal" href="#Overview,-Objectives,-and-Key-Terms">Overview, Objectives, and Key Terms</a><ul>
<li><a class="reference internal" href="#Objectives">Objectives</a></li>
<li><a class="reference internal" href="#Key-Terms">Key Terms</a></li>
</ul>
</li>
<li><a class="reference internal" href="#If,-in-the-beginning,--didn't-go-to-0...">If, in the beginning, <span class="math">\(h\)</span> didn’t go to 0…</a></li>
<li><a class="reference internal" href="#Back-to-Order">Back to Order</a></li>
<li><a class="reference internal" href="#Approximating-the-Second-Derivative">Approximating the Second Derivative</a></li>
<li><a class="reference internal" href="#Finite-Difference-Approximations-of-Arbitrary-Order">Finite-Difference Approximations of Arbitrary Order</a><ul>
<li><a class="reference internal" href="#Simple-Rules">Simple Rules</a></li>
<li><a class="reference internal" href="#Developing-New-Schemes">Developing New Schemes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Further-Reading">Further Reading</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="ME400_Lecture_20.html" title="previous chapter">Lecture 20 - Taylor Series and the Root of Numerical Methods</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/lectures/ME400_Lecture_21.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Jeremy Roberts.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/lectures/ME400_Lecture_21.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>